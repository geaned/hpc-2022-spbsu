# OpenCL --- лекция 1

## Обзор технологии

**Главная идея**: использовать GPU для общих вычислений, а не только для компьютерной графики.

Современные области применения:

- машинное обучение
- маетматические пакеты
- компьютерная графика
- физические движки
- обработка видео
- математическое моделирование
и многие другие

**OpenCL (Open Computing Language)** --- стандарт для написания программ, связанных с паралельными вычислениями. Для разработки, в зависимости от версии OpenCL, используется один из стандартов C/C++.

**CUDA (Computer Unified Device Architecture)** --- архитектура параллельных вычислений от NVIDIA. Для разработки используются языки C/C++, Fortran и другие.

Неотъемлемая часть программы для OpenCL --- файлы с расширением `.cl`, в которых содержится код, исполняемый на GPU (вообще может быть исполнен и на CPU). Этот код можно обернуть в kernel и поставить на исполнение через `.cpp`-файл, содержащий саму программу. Простой пример кода kernel для сложения двух массивов:

```c++
__kernel void vector_add(__global int* a, __global int* b, __global int* c, int n)
{
	int id = get_global_id(0);
	if (id < n)
		c[id] = a[id] + b[id];
}
```

Таким образом, все потоки **выполняют один и тот же код**, причем каждый поток имеет уникальный идентификатор (достается с помощью `get_global_id()`).

Потоки могут взаимодействовать между собой: существует **локальная память** (более быстрая, доступна потокам одного блока) и **локальный барьер** `barrier(CLK_LOCAL_MEM_FENCE)` (есть аналогичный глобальный барьер, но нужно осторожно им пользоваться).

Потоки организованы в **вычислительную сетку**, разбитую на **блоки (рабочие группы)** одинакового размера, внутри которых и происходит взаимодействие блоков.

Внутри kernel можно узнать:

- индекс потока в сетке: `get_global_id()`
- индекс потока в блоке: `get_local_id()`
- размер блока
- индекс блока
- количество блоков
- количество потоков

*Желательно задавать размерности так, чтобы размерность сетки делилась на размерность блока по каждой оси.*

Типы памяти:

- приватная
- регистровая (очень ограниченный размер, самая быстрая, очень высокая пропускная способность)
- локальная (ограниченный размер, быстрая, высокая пропускная способность)
- глобальная (большой размер, медленная, низкая пропускная способность)
- константная (ограниченный размер, быстрая и с высокой пропускной способностью --- но только при попадании в кэш)

В OpenCL также существуют атомарные операции, но они **очень медленные**.

## Архитектура видеокарты

Видеокарта состоит из **потоковых мультипроцессоров (streaming multiprocessor --- SM)**. Каждый потоковый мультипроцессор содержит блок CUDA ядер, небольшой объем разделяемой памяти, а также load/store units и special function units. Каждый SM выполняет вычислительные блоки, ограниченные по их количеству и по общему количеству потоков. При выполнении вычислений блок **разбивается на warps** (один warp --- 32 подряд идущих потока), для управления которыми внутри SM существует **warp scheduler**.

## Простые алгоритмы и паттерны

Как правило, любая операция подчиняется одному из трех паттернов: **map** --- применение функции к каждому элементу, **gather** --- запись функции от нескольких элементов в одну ячейку, **scatter** --- применение одного элемента по нескольку раз в функции от нескольких элементов, результаты которых записываются в разные ячейки.

**Параллельная редукция**: компоновка операций, составляющих вычисление функции от $N$ элементов, в бинарное дерево с временной сложностью $O(\log N)$ и сложностью работы $O(N)$. Реализуется с помощью цикла с последовательно увеличивающимся размером шага и синхронизацией после каждого шага.

**Гистограмма**: пусть дана функция $f: \mathbb{Z} \rightarrow [0, M-1]$, нужно для каждого элемента образа посчитать, сколько элементов из прообраза в него привели. Синхронизировать одну и ту же "корзину" --- очень медленное решение, поэтому главная идея --- посчитать несколько частичных корзин и слиять их с помощью параллельной редукции.
