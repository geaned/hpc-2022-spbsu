# Лекция 3

## Kernel space и user space

Проще всего представлять себе **kernel space** и **user space** через оперативную память: user space часть памяти, выделенная под пользовательский поток, а kernel space --- это память в пространстве ядра ОС, в которой работает тот же поток.

*Уже при запуске `htop` мы видим kernel space и user space; конкретно это видно из того, что загрузка процессора изображена в двух цветах.*

Зачем в общем случае нужно переходить в kernel space? Допустим, в нашем коде выполнилось что-то вроде `new int[10]` (понадобилась дополнительная оперативная память). В kernel space лежит ядро ОС и в нем содержится данные обо всем, что происходит в ОС: участки аллоцированной памяти, планировщик процессов, данные о периферийных устройствах и т.д., в частности, там лежит сам код, доступ к исполнению которого есть в user space и который нужно выполнить, чтобы память была выделена.

Происхдит некоторая противоречивая ситуация: логически была вызывана функция в user space, но реально наш процесс обращается к структурам данных в адресном пространстве другого процесса, а именно процесса ядра ОС. Фактически происходит следующее: номер системного вызова (а выделение памяти --- это системный вызов или же `syscall`) кладется в регистр процессора и вызывается специальная ассемблерная инструкция, которая меняет констекст потока, тем самым позволяя потоку исполнить код ядра и обратиться к его структурам. В это время поток ничего не помнит об изначальном процессе, частью которого он является, и для возврата к исходному состоянию после исполнения кода ядра осуществляется еще одна смена контекста.

*`syscall` --- это дорогая операция, но еще более дорогой операцией является смена контекста потока на ядре. А может ли произойти смена контекста потока на ядре процессора во время `syscall`? Зависит от того, как было собрано ядро ОС: в Linux можно найти флаг `CONFIG_PREEMPT_NONE`, который за это отвечает. По умолчанию это запрещено.*

А зачем при захвате примитива синхронизации потоку нужно переходить в kernel space? Если, к примеру, поток попытается повторно захватить мьютекс, то необходимо снять этот поток с исполнения и поставить на время исполняться другой через планировщик данных в ядре, а это уже `syscall`.

*Функция `yield()` в подавляющем большинстве случаев не приводит к переходу в kernel space: планировщик сам периодически смотрит, выставлен ли у потока флаг, отвечающий за то, что потоку нечего делать.*

## Классификация примитивов синхронизации: продолжение

Примитивы с захватом со временным ограничением `timed_mutex` и `recursive_timed_mutex` при вызове `bool timed_lock()` будут "непрерывно" пытаться захватить примитив в течение определенного времени, в `bool` возвращается наличие успеха при попытке захвата (как в `bool try_lock()` у обычного `mutex`).

**Операция CAS --- compare-and-set (compare-and-swap)** --- с сигнатурой `bool compare_and_set(int*, int, int)` атомарно сравнивает переданное по указателю значение со вторым параметром и в случае равенства присваивает третье. Использование CAS **сильно эффективнее, чем использование отдельного мьютекса**.

CAS дает возможность продолжения захвата примитива без обязательного перехода в режим "ожидания" и, за счет более быстрого исполнения, снижает вероятность столкновения потоков.

Пример использования CAS в боевом коде: `AtomicInteger` в Java. Посмотрим на код:

```java
public final int incrementAndGet() {
	for (;;) {
		int current = get();
		int next = current + 1;
		if (compareAndSet(current, next))	// вызывает get() внутри себя
			return next;
	}
}
```

`spin_mutex` --- примитив, реализованный с помощью CAS (код упрощен):

```c++
inline void spin_mutex::lock(void) {
	do {
		// в CAS в C++ последние два параметра стоят в другом порядке
		// и функция возвращает предыдущее значение проверяемой переменной
		uint32_t prev_s = atomic_cas32(&m_s, 1, 0);
		if (m_s == 1 && prev_s == 0)
			break;
		// ...
	} while (true);
}
```

Первая проверка в условии говорит, захвачен ли примитив, а вторая гарантирует, что он захвачен именно нами.

*А в чем вообще потенциальная польза от подобного примитива синхронизации? При использовании обычного мьютекса при безуспешном `lock()` обязательно произойдет переключение потока на ядре --- очень дорогая операция, поэтому бывает дешевле потратить немного времени и ресурсов в **активном ожидании**. Вообще сейчас большинство блокировок под капотом являются адаптивными: они прогоняют несколько итераций цикла и только потом, если нужно, меняют контекст.*

Идеологию с активным ожиданием в частности переняло ядро ОС и так появился **futex (fast userspace mutex)**, на основе которого в ОС уже строятся другие примитивы синхронизации.

В C++ и других нативных ЯП идиома RAII **справедлива и для примитивов синхронизации**. Так, мьютекс имеет свой `typedef` на `scoped_lock`, в него мы передаем мьютекс, который будет освобожден, когда поток выйдет из данного scope.

`shared_mutex` (он же `rwlock`) необходим в случае, когда относительно структуры данных, с которой мы работаем, есть роли читателя и писателя. Читатели могут параллельно работать со структурой и только, если нет ожидающих писателей, а писатель одновременно может работать только один. Захват на чтение делается с помощью `lock_shared()`, а "дозахват" на запись --- с помощью `lock_upgrade()` (еще есть `lock_upgradeable()`, который **не пропускает больше одного потока, но продолжает пропускать потоки на чтение**), однако такой подход реализован не везде и иногда просто есть отдельная команда на захват на чтение и на захват на запись.

**Условные переменные (conditional variables)** используются для ассоциации примитива синхронизации с некоторым событием. Рассмотрим их применение на примере реализации барьера:

```c++
#define SYNC_MAX_COUNT 10

void SynchronizationPoint() {
	static mutex_t sync_lock = PTHREAD_MUTEX_INITIALIZER;
	static cond_t sync_cond = PTHREAD_COND_INITIALIZER;
	static int sync_count = 0;

	pthread_mutex_lock(&sync_lock);
	sync_count++;

	if (sync_count < SYNC_MAX_COUNT)
		// встаем на ожидание и отдаем примитив синхронизации, а при пробуждении
		// начинаем борьбу за примитив при каждой возможности (здесь: первый раз
		// после broadcast, остальные по очереди после unlock)
		pthread_cond_wait(&sync_cond, &sync_lock);
	else
		// говорим всем потокам на wait пробудиться
		pthread_cond_broadcast(&sync_cond);
	
	pthread_mutex_unlock(&sync_lock);
}
```

Потоки встают на `pthread_cond_wait()` и ждут сигнала, который передается через условную переменную `sync_cond`, с которой можно работать с помощью `pthread_cond_broadcast()` (пробудить **все потоки** на ожидании с этой переменной) или `pthread_cond_signal()` (пробудить **хотя бы один поток** на ожидании с переменной).

Вот еще один пример использования `wait`/`notify` семантики, уже на Java:

```java
public void prepareData() {
	synchronized (monitor) {
		System.out.println("Data prepared");
		ready = true;
		monitor.notifyAll();
	}
}
public void sendData() {
	synchronized (monitor) {
		System.out.println("Waiting for data...");
		while (!ready) {
			try {
				monitor.wait();
			} catch (InterruptedException e) {
				e.printStackTrace();
			}
		}
		System.out.println("Sending data...");
	}
}
```

*Технически в коде на C++ выше можно переставить `pthread_mutex_unlock` перед `pthread_cond_broadcast` (и после `pthread_cond_wait`, чтобы все потоки вышли), хотя и средства поиска ошибок будут выкидывать предупреждение. На Java аналогичный трюк не пройдет: `notifyAll()` должен быть выполнен внутри `synchronized` блока, иначе получим исключение.*

В коде на Java с помощью цикла по флагу `ready` также учтены так называемые **spurious wakeups**, а именно ситуация, при которой поток выходит из `wait()` без `notify()`.
