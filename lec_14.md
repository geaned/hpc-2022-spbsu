# Лекция 14

## Организация параллельных вычислений

**Domain-driven design (DDD)** --- набор принципов, позволящих определить необходимый набор шаблонов для перекладывания предметной области на код.

Этапы разработки многопоточного приложения:
- определить место параллелизма
- выбор необходимого алгоритма или шаблона
- отбор подходящих под реализацию конкурентных структур
- выбор механизма реализации (конкрентная функциональность выбранных фреймворков)

**Основная мысль**: как выбрать механизм реализации под конкретную задачу, чтобы добиться необходимой производительности.

С точки зрения **разделения по данным** огранизация вычисления может быть реализована **линейно и рекурсивно**.

На примере задачи трассировки лучей линейное разделение по данным --- это сопоставление каждому ядру набора лучей, который он должен обработать. Для подобных задач применяется шаблон **геометрической декомпозиции**. Самый простой механизм реализации --- параллельный цикл.

Пример задачи с рекурсивными данными --- поиск корня дерева для каждого листа в лесу. Для этого в каждом листе запускаем свой поток; такое решение подходит особенно в случае, когда в каждом листе выполняется некоторая сложная логика. Шаблон так и называется: **рекурсивные данные**.

**Разделение по задачам (функциональная декомпозиция)** тоже может быть осуществлено **линейно и рекурсивно**.

Возвращаясь к трассировке лучей, разделение по задачам здесь тоже линейное: создаем пул потоков, отражение от каждой поверхности одного луча --- это задача, которую мы кидаем в очередь. Такую идею можно выделить в паттерн **параллелизма на задачах**. Механизмы реализации с очередью задач с помощью паттернов **producer-consumer** (producer кладет задачи), **master-worker** (master готовит задачи) есть в том же TBB. Рекурсивные же задачи решаются по прицнипу **разделяй и властвуй**, который можно реализовать с помощью, например, **деревьев задач**.

Есть класс алгоритмов, ориентированных на **потоковую обработку данных**. Сам поток данных может быть **постоянным и случайным**. Как правило, к первому типу можно отнести системы, получающие данные независимо от пользователя (фиксированное количество камер, детерторов и прочего), а к последнему, наборот, системы, получающие данные от набора пользователей (например, через приложение или веб-интерфейс). В первом случае применяется уже знакомый паттерн **pipeline**, в последнем делается **координация на событиях**.

Еще раз рассмотрим пайплайн с лекции 11 и на его примере разберем, какие паттерны в нем применены:

```c++
parallel_pipeline(threadCount,
	tbb::make_filter<void, std::string*>(
		tbb:filter:serial,
		[&in](tbb::flow_control& fc) -> std::string* {
			auto line = new std::string();
			getline(in, *line);
			if (!in.eof() && line->length() == 0) {
				fc.stop();
				delete line;
				line = 0;
			}
			return line;
		}
	)
	&
	tbb::make_filter<std::string*, std::string*>(
		tbb::filter::parallel,
		[](std::string* line) {
			tbb::parallel_sort(line->begin(), line->end());
			return line;
		}
	)
	&
	tbb::make_filter<std::string*, void>(
		tbb::filter::serial,
		[&out](std::string* line) {
			out << *line << std::endl;
			delete line;
		}
	)
);
```

Во-первых, сам pipeline используется для обработки потоковых данных. Во-вторых, `parallel_sort` во втором фильтре осуществляет геометрическую декомпозицию. В-третьих, само устройство TBB гарантирует, что все задачи в пайплане будут отправлены в пул потоков, использование которого соответствует параллелизму на задачах.

## Шаблон double-check

Пусть мы в многопоточном приложении хотим реализовать загрузку некоторого объекта или синглтон. Если объект уже инициализирован, можно просто его вернуть, а примитив синхронизации тогда захватывать только если объект нужно инициализировать (например, подгрузить некоторый плагин). Примерный код:

```c++
template<typename T, typename Mutex=tbb::mutex>
class lazy {
	tbb::atomic<T*> value;
	Mutex mut;

public:
	lazy(): value() {}

	~lazy() {delete value;}

	T& get() {
		if (!value) {
			Mutex::scoped_lock lock(mut);
			if (!value) value = new T();
		}
		return *value;
	}
};
```

## JIT-оптимизации

Рассмотрим зависимость производительности написанного нами кода от времени его исполнения. Ясно, что для C++ **показатель производительности будет постоянным**, поскольку после компиляции исполняемый код не меняется.

За счет наличия JIT-оптимизаций в Java, код, написанный на этом языке, оптимизируется под поведение системы, однако, на время производительность может и проседать. Как правило это происходит по двум причинам:

- поведение системы изменяется, оптимизации больше не помогают, а скорее, наоборот, заставляют исполняться лишний код, и происходит **деоптимизация**
- происходит автоматическая **сборка мусора** (влияет не так сильно) --- нужно не только освободить память, но и в принципе определить, какие объекты можно разрушать

Если же говорить, о сравнении производительности кода на C++ и на Java, то, как правило, код на C++ исполняется быстрее, хотя в редких ситуациях это не так.

Несколько примеров JIT-оптимизаций для циклов: **вынос условных операторов** из-под цикла и **развертывание (loop unrolling)** --- объединение операций, укладывающихся в одну векторную инструкцию, в одну итерацию цикла.

Существуют и JIT-оптимизации для многопоточного кода, например, **слияние блокировок** одного и того же объекта и **уборка блокировок** (включая тривиальные вроде `synchroinzed (new Object) { ... }`.
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTM2OTU4ODE4OF19
-->
