# Лекция 7

## Барьеры памяти и модели памяти

Для того, чтобы производители процессоров, разработчики компиляторов, разработчики ПО могли договориться, были введены **общеупотребительные барьеры памяти**:

- load-load барьер
- store-load барьер
- load-store барьер
- store-store барьер

В каждом случае все операции типа первой компоненты названия перед барьером будут гарантированно выполнены до всех операций типа второй компоненты названия после барьера.

*Если вспомнить архитектуру процессора с прошлой лекции, то с точки зрения производительности **store-load является самым непроизводительным барьером**, поскольку он заставляет каждое ядро и дождаться всех invalidation acknowledgements, и обработать все invalidate запросы.* 

Вспомним пример с прошлой лекции, в котором при оптимизации работы процессора мы получили возможную ошибку при работе. Какие барьеры можно добавить в функции `f()` и `g()`, чтобы ошибка исчезла? Вот ответ:

```c++
void f() {	// поток [1]
	a = 1;
	// store-store барьер
	b = 1;
}
void g() {	// поток [2]
	while (b == 0)
		continue;
	// load-load барьер
	assert(a == 1);
}
```

Можем ли мы обойтись только load-load барьером во втором потоке? Можем, но это не совсем правильно: барьеры, в частности, влияют на оптимизации компилятора, который тоже может, при желании, переставить операции присваивания значений переменных местами. Также этот барьер лучше поставить на случай, если параллельный поток вместо функции `f()` будет исполнять другую функцию, разработчик которой решил использовать другой барьер, с которым наличие load-load барьера в `g()` уже необходимо.

Пример с аналогичной фабулой для store-load барьера:

```c++
void f() {	// поток [1]
	x = false;
	// store-load барьер
	assert(y);
}
void g() {	// поток [2]
	y = false;
	// store-load барьер
	assert(x);
}
```

Пару барьеров load-load и load-store также называют **acquire**, а пару load-store и store-store --- **release**.

Названия таковы, поскольку можно провести аналогию с примитивами синхронизации: если перед набором инструкций поставить acquire, а после --- release, то **не сможет произойти утечка инструкций** за пределы этих барьеров.

Ясно, что **сам разработчик в коде эти барьеры не ставит**. В зависимости от того, какие барьеры применяются по умолчанию на уровне архитектуры процессора, разделяют четыре **модели памяти**:

- **sequential consistency**: все барьеры памяти применяют после каждого чтения и каждой записи
- **strong-ordered (total store ordering)**: по умолчанию применяется acquire и release (acquire-release семантика); применяется в архитектуре AMD64
- **weak-ordered**: по умолчанию не применяются никакие барьеры памяти; применяется в архитектуре ARM
- **super-weak**: как weak-ordered, только возможно переупорядочивание даже инструкций, зависимых по данным; применяется в архитектуре Alpha

Пусть, как в atomic из C++, нам доступны порядки `acquire`, `release`, `acq_rel` и `seq_cst` (есть еще `relaxed` и `consume`, но их в расчет не берем). Как бы мы применили их в нашем случае относительно уже атомарной переменной `b`, чтобы получить максимально производительный код?

*Атомарная переменная может применять **порядок памяти (memory order)** при операциях чтения или записи.*

```c++
void f() {	// поток [1]
	a = 1;
	b.store(1, release);
}
void g() {	// поток [2]
	while (b.load(0, acquire))
		continue;
	// load-load барьер
	assert(a == 1);
}
```

*Примечание: здесь не нужно думать, когда произойдет сама операция относительно барьеров (до или после). Нужные барьеры встанут там, где нужно. Например, store-store барьер после второго присваивания вообще ничего не поменяет в рамках функции, поэтому логично предположить, что он встанет перед присваиванием.*

Все барьеры памяти обязательно применяются при захвате и освобождении примитивов синхронизации (при CAS-операции тоже) и при смене потока с исполнения на ядре процессора.

## Проблема ABA

Имеем lock-free стек на C++ и два потока:
- первый потокберет указатель на веришну стека `top = m_top`, делает некоторую логику и засыпает
- второй поток делает `pop()` с помощью CAS, потом `push(B)` новой вершины с помощью CAS; за счет оптимизаций аллокатора есть немалая вероятность того, что новосозданный элемент стека **будет помещен в ту же область памяти**, что и тот элемент, который только что был удален
- первый поток просыпается и делает свой CAS: `compare_and_set(m_top, top, newElement)`, причем по логике приложения элемент `newElement` должен быть помещен в стек только если, например, элемента `B` на стеке нету.

Поскольку место под элемент `B` было выделено по тому же адресу, по которому лежала вершина стека изначально, CAS-операция пройдет, что нарушает логику приложения.

*Фактически есть однозначное логическое соответствие между адресами в памяти и данными, которые по ним лежат. Если адреса одинаковые, то и данные по ним должны быть одинаковые. Однако, при данной проблеме этот инвариант рушится.*

На Java данная проблема невозможна, поскольку выполнение `top = m_top` заставит объект, снятый со стека, жить, как минимум пока к нему есть доступ через `top`, а это значит, что и память, занятую этим объектом, пока что никому выделить нельзя.

Как этого избежать на C++? Ссылка, как мы уже устанавливали на пятой лекции, занимает 48 бит, поэтому в остальные 16 бит можно, например, положить счетчик, который будет инкрементироваться при любой операции с этим указателем.

*Вообще это не общее решение не только потому, что в теории из-за переполнения счетчики могут совпасть, но и потому, что такое решение распространяется только на 64-битные системы.*

Для решения подобных проблем существует **SMR (safe memory reclamation)** --- набор схем, которые помогают определить, когда на самом деле можно безопасно высвободить память. В данном случае полезна схема SMR под названием [**tagged pointer**](https://habr.com/ru/post/202190/) (еще есть **hazard pointer** для той же цели).

## Линеаризуемость

**Точка линеаризации** --- операция, после которой результаты всей логической операции становятся видны другим потокам (например, тот же CAS).

Саму **линеаризуемость** удобно воспринимать, как возможность получения параллельного исполнения многопоточного процесса **хотя бы одним возможным последовательным исполнением**.

![lec_07_1](https://i.imgur.com/3Rtpol2.png)
Выше представлен пример двух исполнений многопоточной программы, использующей конкуррентный счетчик, не удовлетворяющих логике счетчика, и исполнение, удовлетворяющее логике с отмеченными возможными точками линеризации.

## Очередь Майкла-Скотта

В структуре очереди храним две ссылки: на начало `head` и на конец `tail` очереди. Изначально для удобства реализации и начало, и конец указывают на "пустышку".

При добавлении мы делаем два CAS:

- меняем указатель `next` последнего элемента с `NULL` на адрес нового элемента (последний элемент мог поменяться)
- меняем значение `tail` на адрес нового элемента, но **не только в этом потоке** (мог добавиться другой хвост, но при такой реализации **реальный хвост всегда будет отличаться не более, чем на один элемент**)

При удалении мы делаем один CAS, а именно приравниваем `head` к адресу первого элемента, после чего данные забираем (первый элемент становится "пустышкой").

Вот код реализации методов вставки и удаления на Java:

```java
public boolean enq(T value) {
	Node = new Node(value);
	retry@while (true) {
		Node last = tail.get();
		Node next = last.next.get();
		if (last == tail.get()) {
			if (next == null) {
				// в Java, в отличие от C++, порядок агрументов в CAS такой же, как в определении
				// в лекции 3 (разве что функция вызывается прямо у сравниваемого элемента, который
				// в том определении стоял первым аргументом)
				if (!last.next.compareAndSet(null, node))
					continue@retry;
				tail.compareAndSet(last, node);
				return true;
			} else {
				tail.compareAndSet(last, next);	// помогаем перевесить хвост
			}
		}
	}
}

public T deq() throws EmptyException {
	while (true) {
		Node first = head.get();
		Node last = tail.get();
		Node next = first.next.get();
		if (first == last) {	// очередь пуста
			if (next == null) {
				throw new EmptyException();
			}
			tail.compareAndSet(last, next); // помогаем перевесить хвост
		} else {	// очередь не пуста, смотрим на первый элемент
			T value = next.value;
			if (head.compareAndSet(first, next))
				return value;
		}
	}
}
```
