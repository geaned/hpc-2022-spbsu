# OpenCL-2

## Операция scan

Рассмотрим операцию `scan()`: пусть на вход подается массив из $N$ элементов $[a_0, ..., a_{N-1}]$, и к ним нужно применить бинарный ассоциативный оператор $\bigoplus$ с единицей $I$. Разделяют **exclusive scan** и **inclusive scan**: первый возвращает $[I, a_0, ..., a_0 \bigoplus ... \bigoplus a_{N-2}]$, а второй --- $[a_0, a_0 \bigoplus a_1, ..., a_0 \bigoplus ... \bigoplus a_{N-1}]$.

Последовательная реализация тривиальна, но неэффективна. Существуют параллельные реализации **Hillis-Steele scan** и **Blelloch scan**.

Первый чуть более наивен, у него большая рабочая сложность --- $O(N\log N)$ против $O(N)$ --- при вдвое меньшей сложности по времени. Первый алгоритм --- это фактически параллельная редукция, второй чуть более изощрен: с уменьшающимся шагом на каждом этапе мы переносим некоторые элементы справа левее, потом на их место пишем сумму.

Как быть, если нам нужно проделать `scan()` на большом количестве элементов, не помещающихся в локальную память, с сохранением возможной производительности? Сделаем `scan()` поблочно, потом сделаем промежуточный `scan()` на поблочных максимумах и добавим промежуточный результат к поблочному.

С помощью `scan()` реализуются следующие алгоритмы:
- `compact()` --- возвращает элементы с поднятым флагом в соответствующем массиве с сохранением порядка)
- поразрядная сортировка
- сортировка слиянием

## Битоническая сортировка

**Сравнивающее устройство (компаратор)** --- черный ящик, получающий на вход два числа и возвращающий наименьшее из них на выход минимума, а другое --- на выход максимума.

**Сортирующая сеть** --- метод сортировки, основанный только на сравнении данных. Графически изображается с помощью параллельных прямых, соответствующих переменным, соединенных проводами, обозначающими сравнивающие устройства.

**Теорема ("0-1 принцип")**: если сеть компараторов сортирует все последовательности из нулей и единиц, то она сортирующая.

**Битоническая последовательность** --- последовательность чисел, которая сначала возврастает, потом убывает, или которая приводится к такой циклическим сдвигом.

## Оптимизации

Потоки запускаются группами, и в случае ветвления соответствующие инструкции внутри группы будут выполняться последовательно, поэтому если смысл постараться сделать так, чтобы внутри группы условие ветвления было **одинаковым для всех потоков**.

Также на производительность влияет количество **конфликтов обращений к банкам памяти**.

Следующая оптимизация чуть менее тривиальная: сделать **развертку циклов**. Дело в том, что при работе с малыми группами потоков, можно не использовать барьеры памяти, потому что они фактически будут присутствовать априори благодаря SIMD архитектуре варпов в GPU (нужно делать аккуратно, есть зависимость от архитектуры видеокарты).

Более технически сложные оптимизации:

- параллелизм на уровне инструкций
- асинхронная передача данных
- ключевое слово restrict
- выбор типов данных (интересные примеры: `half` вместо `float`, `int` вместо `uint` из-за наличия проверки переполнения для `uint`)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTk5Nzc2MjU4MV19
-->
